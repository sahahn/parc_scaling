{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "confirmed-philadelphia",
   "metadata": {},
   "source": [
    "# Interactive Plots\n",
    "\n",
    "This notebook is used to generate interactive visualizations with the python plotly library for use in the online documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "corresponding-courage",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sage/anaconda3/envs/bpt/lib/python3.9/site-packages/nilearn/datasets/__init__.py:93: FutureWarning: Fetchers from the nilearn.datasets module will be updated in version 0.9 to return python strings instead of bytes and Pandas dataframes instead of Numpy arrays.\n",
      "  warn(\"Fetchers from the nilearn.datasets module will be \"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from itertools import cycle\n",
    "\n",
    "from plot_funcs import (get_results, get_ranks_sizes,\n",
    "                        get_highest_performing_df, get_cut_off_df,\n",
    "                        get_across_ranks, get_intra_pipeline_df,\n",
    "                        get_single_vs_multiple_df, get_results_df,\n",
    "                        get_single_vs_multiple_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "statutory-affairs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: 87390 Incomplete: 0\n"
     ]
    }
   ],
   "source": [
    "results = get_results('../exp/results')\n",
    "\n",
    "static = {'random': True, 'base': True, 'fs': True, 'ico': True}\n",
    "ensemble_only = {'stacked': True, 'voted': True}\n",
    "all_parcels = {**static, **ensemble_only, 'grid': True}\n",
    "\n",
    "params = dict(results=results, keep_full_name=True, threshold=False, **static)\n",
    "\n",
    "ts = [True, True, True, True]\n",
    "fs = [False, False, False, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "scenic-audit",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_fig(ylabel='Mean Rank'):\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    fig.layout.xaxis.title = 'Size'\n",
    "    fig.layout.yaxis.title = ylabel\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def add_base_side_annot(fig, buttons):\n",
    "    \n",
    "    # Add dropdown\n",
    "    fig.update_layout(\n",
    "        updatemenus=[\n",
    "            dict(\n",
    "                type = \"buttons\",\n",
    "                direction = \"left\",\n",
    "                buttons=buttons,\n",
    "                pad={\"r\": 10, \"t\": 10},\n",
    "                showactive=True,\n",
    "                x=0.11,\n",
    "                xanchor=\"left\",\n",
    "                y=1.1,\n",
    "                yanchor=\"top\"\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Add annotation\n",
    "    fig.update_layout(\n",
    "        annotations=[\n",
    "            dict(text=\"Scale:\", showarrow=False,\n",
    "                 x=0, y=1.08, yref=\"paper\", align=\"left\")\n",
    "        ]\n",
    "    )\n",
    "\n",
    "def add_go_base_scatter(fig, name, df, visible, y='Mean_Rank', marker_size=20):\n",
    "    \n",
    "    gs = go.Scatter(\n",
    "            x=df['Size'],\n",
    "            y=df[y],\n",
    "            visible=visible,\n",
    "            mode='markers',\n",
    "            name=name,\n",
    "            hovertext=df['full_name'],\n",
    "            textposition=\"middle center\",\n",
    "            customdata=np.stack((df['r2'],\n",
    "                                 df['roc_auc'],\n",
    "                                 df['rank_label'],\n",
    "                                 df['size_label']), axis=-1),\n",
    "            hovertemplate='<b>%{hovertext}</b><br>' +\n",
    "                          '%{customdata[2]}<br>' +\n",
    "                          '%{customdata[3]}<br>' +\n",
    "                          'Mean R2: %{customdata[0]:.4f}<br>' +\n",
    "                          'Mean ROC AUC: %{customdata[1]:.4f}<br>' +\n",
    "                          '<extra></extra>')\n",
    "\n",
    "    gs.marker.size = marker_size\n",
    "    gs.marker.opacity = .5\n",
    "\n",
    "    # Add plot\n",
    "    fig.add_trace(gs)\n",
    "    \n",
    "def add_go_by_target_scatter(fig, name, df, visible,\n",
    "                             palette, y='Mean_Rank',\n",
    "                             marker_size=20):\n",
    "    \n",
    "    gs = go.Scatter(\n",
    "            x=df['Size'],\n",
    "            y=df[y],\n",
    "            visible=visible,\n",
    "            mode='markers',\n",
    "            name=name,\n",
    "            text=df['full_name'],\n",
    "            customdata=np.stack((df['rank_label'],\n",
    "                                 df['size_label'],\n",
    "                                 df['Mean_Score']), axis=-1),\n",
    "            hovertemplate='<b>%{text}</b><br>' +\n",
    "                          '<b>' + name + '</b><br>' + \n",
    "                          '%{customdata[0]}<br>' +\n",
    "                          '%{customdata[1]}<br>' +\n",
    "                          'Mean Raw Metric: %{customdata[2]:.4f}<extra></extra>')\n",
    "\n",
    "    gs.marker.size = marker_size\n",
    "    gs.marker.opacity = .25\n",
    "    gs.marker.color = next(palette)\n",
    "\n",
    "    # Add plot\n",
    "    fig.add_trace(gs)\n",
    "    \n",
    "def by_pipeline_base(metric_type='Mean_Rank', marker_size=20,\n",
    "                     xrange=(.5, 4), yrange=(1.2, 2.8),\n",
    "                     log=True, **parcels):\n",
    "    \n",
    "    models = ['LGBM', 'SVM', 'Elastic-Net', 'All']\n",
    "\n",
    "    fig_dict = {\n",
    "        \"data\": [],\n",
    "        \"layout\": {},\n",
    "        \"frames\": []\n",
    "    }\n",
    "    \n",
    "    # Get ylabel\n",
    "    if metric_type == 'Mean_Rank':\n",
    "        ylabel = 'Mean Rank'\n",
    "        log_raw = False\n",
    "    elif metric_type == 'r2':\n",
    "        ylabel = 'Mean R2'\n",
    "        log_raw = True\n",
    "    elif metric_type == 'roc_auc':\n",
    "        ylabel = 'Mean ROC AUC'\n",
    "        log_raw = True\n",
    "        \n",
    "        \n",
    "    extra = ' (log10)'\n",
    "    if not log:\n",
    "        log_raw = False\n",
    "        extra = ''\n",
    "\n",
    "    fig_dict[\"layout\"][\"xaxis\"] = {\"range\": xrange, \"title\": f\"Size{extra}\"}\n",
    "    fig_dict[\"layout\"][\"yaxis\"] = {\"range\": yrange, \"title\": f\"{ylabel}{extra}\"}\n",
    "    fig_dict[\"layout\"][\"hovermode\"] = \"closest\"\n",
    "\n",
    "    sliders_dict = {\n",
    "        \"active\": 0,\n",
    "        \"yanchor\": \"top\",\n",
    "        \"xanchor\": \"left\",\n",
    "        \"currentvalue\": {\n",
    "            \"font\": {\"size\": 20},\n",
    "            \"prefix\": \"Pipeline:\",\n",
    "            \"visible\": True,\n",
    "            \"xanchor\": \"right\"\n",
    "        },\n",
    "        \"pad\": {\"b\": 10, \"t\": 50},\n",
    "        \"len\": 0.9,\n",
    "        \"x\": 0.1,\n",
    "        \"y\": 0,\n",
    "        \"steps\": []\n",
    "    }\n",
    "\n",
    "    def get_data_dicts(pipeline):\n",
    "\n",
    "        if pipeline == 'All':\n",
    "            models = 'default'\n",
    "        elif pipeline == 'Elastic-Net':\n",
    "            models = ['elastic']\n",
    "        elif pipeline == 'LGBM':\n",
    "            models = ['lgbm']\n",
    "        else:\n",
    "            models = ['svm']\n",
    "\n",
    "        r_df = get_ranks_sizes(results=results,\n",
    "                               keep_full_name=True, threshold=False,\n",
    "                               log=log, log_raw=log_raw,\n",
    "                               add_ranks_labels=True,\n",
    "                               add_raw=True, models=models, **parcels)\n",
    "\n",
    "        data_dicts = []\n",
    "        for name, df in r_df.groupby('Parcellation_Type'):\n",
    "            data_dict = {\n",
    "                'x': df['Size'],\n",
    "                'y': df[metric_type],\n",
    "                'mode': \"markers\",\n",
    "                'text': df['full_name'],\n",
    "                \"marker\": {\n",
    "                    \"size\": marker_size,\n",
    "                    \"opacity\": .5\n",
    "                },\n",
    "                \"customdata\": np.stack((df['r2'],\n",
    "                                        df['roc_auc'],\n",
    "                                        df['rank_label'],\n",
    "                                        df['size_label']), axis=-1),\n",
    "                'name': name,\n",
    "                'hovertemplate': '<b>%{text}</b><br>' +\n",
    "                                 '%{customdata[2]}<br>' +\n",
    "                                 '%{customdata[3]}<br>' +\n",
    "                                 'Mean R2: %{customdata[0]:.4f}<br>' +\n",
    "                                 'Mean ROC AUC: %{customdata[1]:.4f}<br>' +\n",
    "                                 '<extra></extra>'\n",
    "            }\n",
    "\n",
    "            data_dicts.append(data_dict)\n",
    "\n",
    "        return data_dicts\n",
    "\n",
    "    # make init data\n",
    "    fig_dict[\"data\"] = get_data_dicts(pipeline='LGBM')\n",
    "\n",
    "    # make frames\n",
    "    for model in models:\n",
    "        frame = {\"data\": [], \"name\": str(model)}\n",
    "\n",
    "        frame['data'] = get_data_dicts(model)\n",
    "        fig_dict[\"frames\"].append(frame)\n",
    "\n",
    "        slider_step = {\"args\": [\n",
    "            [model],\n",
    "            {\"frame\": {\"duration\": 1000, \"redraw\": False},\n",
    "             \"transition\": {\"duration\": 1000}}\n",
    "        ],\n",
    "            \"label\": model,\n",
    "            \"method\": \"animate\"}\n",
    "\n",
    "        sliders_dict[\"steps\"].append(slider_step)\n",
    "\n",
    "    fig_dict[\"layout\"][\"sliders\"] = [sliders_dict]\n",
    "    fig = go.Figure(fig_dict)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def proc_metric_type(metric_type):\n",
    "        \n",
    "    if metric_type == 'r2':\n",
    "        return 'Mean R2', True\n",
    "    \n",
    "    elif metric_type == 'roc_auc':\n",
    "        return 'Mean ROC AUC', True\n",
    "\n",
    "    return 'Mean Rank', False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "requested-instrumentation",
   "metadata": {},
   "source": [
    "## Base Single Parcellations -  log toggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "rural-pharmacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_single_parcel_fig(metric_type='Mean_Rank', marker_size=20):\n",
    "    \n",
    "    # Set by metric type\n",
    "    ylabel, log_raw = proc_metric_type(metric_type)\n",
    "    \n",
    "    # Init\n",
    "    fig = init_fig(ylabel)\n",
    "\n",
    "    def add_traces(r_df, visible=False):\n",
    "        for name, df in r_df.groupby('Parcellation_Type'):\n",
    "            add_go_base_scatter(fig, name, df, visible, y=metric_type, marker_size=marker_size)\n",
    "\n",
    "    # Keep track of buttons\n",
    "    buttons = []\n",
    "\n",
    "    # Base\n",
    "    add_traces(get_ranks_sizes(**params, add_raw=True,\n",
    "                               log=False, log_raw=False,\n",
    "                               add_ranks_labels=True), visible=True)\n",
    "    buttons.append(dict(args=[{\"visible\": ts + fs}],\n",
    "                        label='Base',\n",
    "                        method=\"update\"))\n",
    "\n",
    "    # Log10\n",
    "    add_traces(get_ranks_sizes(**params, add_raw=True,\n",
    "                               log=True, log_raw=log_raw,\n",
    "                               add_ranks_labels=True), visible=False)\n",
    "    buttons.append(dict(args=[{\"visible\": fs + ts}],\n",
    "                        label='Log',\n",
    "                        method=\"update\"))\n",
    "\n",
    "    # Add base side dropdown + annot\n",
    "    add_base_side_annot(fig, buttons)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "#plotly.offline.plot(gen_single_parcel_fig('Mean_Rank', marker_size=20))\n",
    "gen_single_parcel_fig('Mean_Rank', marker_size=20).write_html('../docs/interactive1.html')\n",
    "gen_single_parcel_fig('r2', marker_size=20).write_html('../docs/interactive1_r2.html')\n",
    "gen_single_parcel_fig('roc_auc', marker_size=20).write_html('../docs/interactive1_roc_auc.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floral-economy",
   "metadata": {},
   "source": [
    "## Base Single Parcellations - by pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "thermal-client",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved: ../docs/_includes/interactive2.html\n",
      "saved: ../docs/interactive2.html\n",
      "saved: ../docs/_includes/interactive2_base.html\n",
      "saved: ../docs/interactive2_base.html\n",
      "saved: ../docs/_includes/interactive2_r2.html\n",
      "saved: ../docs/interactive2_r2.html\n",
      "saved: ../docs/_includes/interactive2_base_r2.html\n",
      "saved: ../docs/interactive2_base_r2.html\n",
      "saved: ../docs/_includes/interactive2_roc_auc.html\n",
      "saved: ../docs/interactive2_roc_auc.html\n",
      "saved: ../docs/_includes/interactive2_base_roc_auc.html\n",
      "saved: ../docs/interactive2_base_roc_auc.html\n"
     ]
    }
   ],
   "source": [
    "def gen_pipeline_fig(metric_type='Mean_Rank', marker_size=20, log=True):\n",
    "    \n",
    "    if log:\n",
    "        \n",
    "        if metric_type == 'Mean_Rank':\n",
    "            yrange = (1.25, 2.5)\n",
    "        elif metric_type == 'r2':\n",
    "            yrange = (-1.8, -.9)\n",
    "        elif metric_type == 'roc_auc':\n",
    "            yrange = (-.28, -.18)\n",
    "            \n",
    "        xrange = (.5, 4)\n",
    "\n",
    "    else:\n",
    "        \n",
    "        if metric_type == 'Mean_Rank':\n",
    "            yrange = (1, 230)\n",
    "        elif metric_type == 'r2':\n",
    "            yrange = (0, .15)\n",
    "        elif metric_type == 'roc_auc':\n",
    "            yrange = (.52, .66)\n",
    "            \n",
    "        xrange = (-250, 6250)\n",
    "    \n",
    "    return by_pipeline_base(metric_type,\n",
    "                            marker_size=marker_size,\n",
    "                            yrange=yrange,\n",
    "                            xrange=xrange,\n",
    "                            log=log,\n",
    "                            **static)\n",
    "\n",
    "def save_all(gen_func, base_num):\n",
    "    \n",
    "    for metric in ['Mean_Rank', 'r2', 'roc_auc']:\n",
    "        for log in [True, False]:\n",
    "            for marker_size in [10, 20]:\n",
    "                \n",
    "                # Gen figure\n",
    "                fig = gen_func(metric, log=log, marker_size=marker_size)\n",
    "                \n",
    "                # Get different save tags\n",
    "                base_tag = ''\n",
    "                if not log:\n",
    "                    base_tag = '_base'\n",
    "                    \n",
    "                metric_tag = ''\n",
    "                if metric != 'Mean_Rank':\n",
    "                    metric_tag = f'_{metric}'\n",
    "                    \n",
    "                includes_tag = ''\n",
    "                if marker_size == 10:\n",
    "                    includes_tag = '_includes/'\n",
    "                \n",
    "                # Save\n",
    "                save_loc = f'../docs/{includes_tag}interactive{base_num}{base_tag}{metric_tag}.html'\n",
    "                fig.write_html(save_loc)\n",
    "                print('saved:', save_loc)\n",
    "\n",
    "\n",
    "#plotly.offline.plot(gen_pipeline_fig('Mean_Rank', marker_size=20, log=False))\n",
    "#plotly.offline.plot(gen_pipeline_fig('r2', marker_size=20, log=False))\n",
    "#plotly.offline.plot(gen_pipeline_fig('roc_auc', marker_size=20, log=False))\n",
    "\n",
    "save_all(gen_pipeline_fig, '2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "following-moscow",
   "metadata": {},
   "source": [
    "## By Target - avg over pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "potential-henry",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_target_fig(marker_size=15, metric='Mean_Rank', **parcels):\n",
    "    \n",
    "    if metric == 'Mean_Rank':\n",
    "        \n",
    "        ylabel = 'Mean Rank'\n",
    "        binary_only = False\n",
    "        regression_only = False\n",
    "        y = 'Mean_Rank'\n",
    "        n = 45\n",
    "        \n",
    "    elif metric == 'r2':\n",
    "        \n",
    "        ylabel = 'Mean R2'\n",
    "        binary_only = False\n",
    "        regression_only = True\n",
    "        y = 'Mean_Score'\n",
    "        n = 22\n",
    "\n",
    "    elif metric == 'roc_auc':\n",
    "        \n",
    "        ylabel = 'Mean ROC AUC'\n",
    "        binary_only = True\n",
    "        regression_only = False\n",
    "        y = 'Mean_Score'\n",
    "        n = 23\n",
    "\n",
    "    fig = init_fig(ylabel=ylabel)\n",
    "    \n",
    "    def add_traces(r_df, y, visible=False):\n",
    "        \n",
    "        # Fixed colors\n",
    "        palette = cycle(px.colors.qualitative.D3)\n",
    "\n",
    "        # By target here\n",
    "        for name, df in r_df.groupby('target'):\n",
    "            add_go_by_target_scatter(fig, name, df, visible,\n",
    "                                     palette, y=y,\n",
    "                                     marker_size=marker_size)\n",
    "\n",
    "    # Keep track of buttons\n",
    "    buttons = []\n",
    "    \n",
    "    # Params to pass to get rank sizes\n",
    "    params = {'results': results,\n",
    "              'keep_full_name': True,\n",
    "              'threshold': False,\n",
    "              'avg_targets': False,\n",
    "              'add_ranks_labels': True,\n",
    "              'add_raw': False,\n",
    "              'binary_only': binary_only,\n",
    "              'regression_only': regression_only,\n",
    "              **parcels}\n",
    "\n",
    "    # Base\n",
    "    add_traces(get_ranks_sizes(log=False, **params), y=y, visible=True)\n",
    "    buttons.append(dict(args=[{\"visible\": ([True]*n) + ([False]*n)}],\n",
    "                        label='Base', method=\"update\"))\n",
    "\n",
    "    # Log10\n",
    "    add_traces(get_ranks_sizes(log=True, log_raw=True, **params), y=y, visible=False)\n",
    "    buttons.append(dict(args=[{\"visible\": ([False]*n) + ([True]*n)}],\n",
    "                        label='Log', method=\"update\"))\n",
    "\n",
    "    # Add base side dropdown + annot\n",
    "    add_base_side_annot(fig, buttons)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "#plotly.offline.plot(make_target_fig(marker_size=15, metric='Mean_Rank', **static))\n",
    "#plotly.offline.plot(make_target_fig(marker_size=15, metric='r2', **static))\n",
    "#plotly.offline.plot(make_target_fig(marker_size=15, metric='roc_auc', **static))\n",
    "\n",
    "make_target_fig(marker_size=15, metric='Mean_Rank', **static).write_html('../docs/interactive3.html')\n",
    "make_target_fig(marker_size=15, metric='r2', **static).write_html('../docs/interactive3_r2.html')\n",
    "make_target_fig(marker_size=15, metric='roc_auc', **static).write_html('../docs/interactive3_roc_auc.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certain-burst",
   "metadata": {},
   "source": [
    "## All - base w/ log toggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "polar-seeking",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_multi_parcel_fig(metric_type='Mean_Rank', marker_size=20):\n",
    "    \n",
    "    # Set by metric type\n",
    "    ylabel, log_raw = proc_metric_type(metric_type)\n",
    "    \n",
    "    # Init\n",
    "    fig = init_fig(ylabel)\n",
    "\n",
    "    def add_traces(r_df, visible=False):\n",
    "        for name, df in r_df.groupby('Parcellation_Type'):\n",
    "            add_go_base_scatter(fig, name, df, visible, y=metric_type, marker_size=marker_size)\n",
    "\n",
    "    # Keep track of buttons\n",
    "    buttons = []\n",
    "    \n",
    "    # Base\n",
    "    r_df = get_single_vs_multiple_df(log=False, add_raw=True, add_ranks_labels=True,\n",
    "                                     stacked=True, voted=True, grid=True,\n",
    "                                     **params).reset_index()\n",
    "    add_traces(r_df, visible=True)\n",
    "    \n",
    "    buttons.append(dict(args=[{\"visible\": ts + fs}],\n",
    "                        label='Base',\n",
    "                        method=\"update\"))\n",
    "\n",
    "    # Log10\n",
    "    r_df = get_single_vs_multiple_df(log=True, log_raw=log_raw, add_raw=True,\n",
    "                                     add_ranks_labels=True,\n",
    "                                     stacked=True, voted=True, grid=True,\n",
    "                                     **params).reset_index()\n",
    "    add_traces(r_df, visible=False)\n",
    "\n",
    "    buttons.append(dict(args=[{\"visible\": fs + ts}],\n",
    "                        label='Log',\n",
    "                        method=\"update\"))\n",
    "\n",
    "    # Add base side dropdown + annot\n",
    "    add_base_side_annot(fig, buttons)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "#plotly.offline.plot(gen_multi_parcel_fig(metric_type='roc_auc', marker_size=20))\n",
    "\n",
    "gen_multi_parcel_fig(marker_size=20).write_html('../docs/interactive4.html')\n",
    "gen_multi_parcel_fig(metric_type='r2', marker_size=20).write_html('../docs/interactive4_r2.html')\n",
    "gen_multi_parcel_fig(metric_type='roc_auc', marker_size=20).write_html('../docs/interactive4_roc_auc.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-south",
   "metadata": {},
   "source": [
    "## All - by pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abroad-court",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved: ../docs/_includes/interactive5.html\n",
      "saved: ../docs/interactive5.html\n",
      "saved: ../docs/_includes/interactive5_base.html\n",
      "saved: ../docs/interactive5_base.html\n",
      "saved: ../docs/_includes/interactive5_r2.html\n",
      "saved: ../docs/interactive5_r2.html\n",
      "saved: ../docs/_includes/interactive5_base_r2.html\n",
      "saved: ../docs/interactive5_base_r2.html\n",
      "saved: ../docs/_includes/interactive5_roc_auc.html\n",
      "saved: ../docs/interactive5_roc_auc.html\n",
      "saved: ../docs/_includes/interactive5_base_roc_auc.html\n",
      "saved: ../docs/interactive5_base_roc_auc.html\n"
     ]
    }
   ],
   "source": [
    "def gen_all_pipeline_fig(metric_type='Mean_Rank',\n",
    "                         marker_size=20, log=True):\n",
    "    \n",
    "    if log:\n",
    "        \n",
    "        if metric_type == 'Mean_Rank':\n",
    "            yrange = (1.1, 2.9)\n",
    "        elif metric_type == 'r2':\n",
    "            yrange = (-1.9, -.8)\n",
    "        elif metric_type == 'roc_auc':\n",
    "            yrange = (-.30, -.16)\n",
    "            \n",
    "        xrange = (.6, 4)\n",
    "\n",
    "    else:\n",
    "        \n",
    "        if metric_type == 'Mean_Rank':\n",
    "            yrange = (1, 450)\n",
    "        elif metric_type == 'r2':\n",
    "            yrange = (0, .12)\n",
    "        elif metric_type == 'roc_auc':\n",
    "            yrange = (.52, .66)\n",
    "            \n",
    "        xrange = (-250, 8000)\n",
    "    \n",
    "    return by_pipeline_base(metric_type,\n",
    "                            marker_size=marker_size,\n",
    "                            yrange=yrange,\n",
    "                            xrange=xrange,\n",
    "                            log=log,\n",
    "                            **all_parcels)\n",
    "\n",
    "#plotly.offline.plot(gen_all_pipeline_fig(metric_type='Mean_Rank', marker_size=20, log=True))\n",
    "#plotly.offline.plot(gen_all_pipeline_fig(metric_type='Mean_Rank', marker_size=20, log=False))\n",
    "\n",
    "#plotly.offline.plot(gen_all_pipeline_fig(metric_type='r2', marker_size=20, log=True))\n",
    "#plotly.offline.plot(gen_all_pipeline_fig(metric_type='r2', marker_size=20, log=False))\n",
    "\n",
    "#plotly.offline.plot(gen_all_pipeline_fig(metric_type='roc_auc', marker_size=20, log=True))\n",
    "#plotly.offline.plot(gen_all_pipeline_fig(metric_type='roc_auc', marker_size=20, log=False))\n",
    "\n",
    "save_all(gen_func=gen_all_pipeline_fig, base_num='5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "underlying-junior",
   "metadata": {},
   "source": [
    "## Ensemble - by pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "determined-sponsorship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved: ../docs/_includes/interactive6.html\n",
      "saved: ../docs/interactive6.html\n",
      "saved: ../docs/_includes/interactive6_base.html\n",
      "saved: ../docs/interactive6_base.html\n",
      "saved: ../docs/_includes/interactive6_r2.html\n",
      "saved: ../docs/interactive6_r2.html\n",
      "saved: ../docs/_includes/interactive6_base_r2.html\n",
      "saved: ../docs/interactive6_base_r2.html\n",
      "saved: ../docs/_includes/interactive6_roc_auc.html\n",
      "saved: ../docs/interactive6_roc_auc.html\n",
      "saved: ../docs/_includes/interactive6_base_roc_auc.html\n",
      "saved: ../docs/interactive6_base_roc_auc.html\n"
     ]
    }
   ],
   "source": [
    "def gen_ensemble_only_pipeline_fig(metric_type='Mean_Rank',\n",
    "                                   marker_size=20, log=True):\n",
    "    \n",
    "    if log:\n",
    "\n",
    "        if metric_type == 'Mean_Rank':\n",
    "            yrange = (1.2, 2.4)\n",
    "        elif metric_type == 'r2':\n",
    "            yrange = (-1.6, -.8)\n",
    "        elif metric_type == 'roc_auc':\n",
    "            yrange = (-.27, -.16)\n",
    "            \n",
    "        xrange = (2.3, 4)\n",
    "\n",
    "    else:\n",
    "        \n",
    "        if metric_type == 'Mean_Rank':\n",
    "            yrange = (1, 125)\n",
    "        elif metric_type == 'r2':\n",
    "            yrange = (.04, .12)\n",
    "        elif metric_type == 'roc_auc':\n",
    "            yrange = (.56, .66)\n",
    "            \n",
    "        xrange = (300, 8000)\n",
    "    \n",
    "    return by_pipeline_base(metric_type,\n",
    "                            marker_size=marker_size,\n",
    "                            yrange=yrange,\n",
    "                            xrange=xrange,\n",
    "                            log=log,\n",
    "                            **ensemble_only)\n",
    "\n",
    "#plotly.offline.plot(gen_ensemble_only_pipeline_fig(metric_type='Mean_Rank', marker_size=20, log=True))\n",
    "#plotly.offline.plot(gen_ensemble_only_pipeline_fig(metric_type='Mean_Rank', marker_size=20, log=False))\n",
    "\n",
    "#plotly.offline.plot(gen_ensemble_only_pipeline_fig(metric_type='r2', marker_size=20, log=True))\n",
    "#plotly.offline.plot(gen_ensemble_only_pipeline_fig(metric_type='r2', marker_size=20, log=False))\n",
    "\n",
    "#plotly.offline.plot(gen_ensemble_only_pipeline_fig(metric_type='roc_auc', marker_size=20, log=True))\n",
    "#plotly.offline.plot(gen_ensemble_only_pipeline_fig(metric_type='roc_auc', marker_size=20, log=False))\n",
    "\n",
    "save_all(gen_func=gen_ensemble_only_pipeline_fig, base_num='6')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "settled-compact",
   "metadata": {},
   "source": [
    "## All By Target - avg over pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "chronic-session",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotly.offline.plot(make_target_fig(metric='Mean_Rank', marker_size=15, **all_parcels))\n",
    "#plotly.offline.plot(make_target_fig(metric='r2', marker_size=15, **all_parcels))\n",
    "#plotly.offline.plot(make_target_fig(metric='roc_auc', marker_size=15, **all_parcels))\n",
    "\n",
    "make_target_fig(metric='Mean_Rank', marker_size=15, **all_parcels).write_html('../docs/interactive7.html')\n",
    "make_target_fig(metric='r2', marker_size=15, **all_parcels).write_html('../docs/interactive7_r2.html')\n",
    "make_target_fig(metric='roc_auc', marker_size=15, **all_parcels).write_html('../docs/interactive7_roc_auc.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('bpt': conda)",
   "language": "python",
   "name": "python391jvsc74a57bd0816e2859f723fb77ad3214da0fbda681e8d4db93bd8b118618b521c0b1f5f48f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
